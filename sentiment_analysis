{
 "cells": [
  {
   "cell_type": "raw",
   "id": "05a5ffed",
   "metadata": {},
   "source": [
    "The data ‘sentiment.csv’ contains all information about the tweet, but for\n",
    "this exercise, use the text and sentiment(only positive and negative\n",
    "sentiments) columns. Perform all the necessary data cleaning required and\n",
    "answer the questions below:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c3b3328",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71cb5910",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import math\n",
    "from nltk import sent_tokenize, word_tokenize, PorterStemmer\n",
    "from nltk.corpus import stopwords \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import keras\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5780f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b113710",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"D:/Imarticus/Jupyter notebook/Paper2/Sentiment.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "775ab118",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0930ae22",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"sentiment\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cfea108",
   "metadata": {},
   "source": [
    "### 1) Total Number of Positive and Negative Sentiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac731494",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_count = 0\n",
    "n_count = 0\n",
    "for i in df[\"sentiment\"]:\n",
    "    if i == \"Positive\":\n",
    "        p_count += 1\n",
    "    elif i == \"Negative\":\n",
    "        n_count += 1\n",
    "print(\"Positive count : \", p_count)\n",
    "print(\"Negative count : \", n_count)\n",
    "print(\"Total positive and negative count : \", p_count + n_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2caded3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df[\"sentiment\"] != \"Neutral\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b7c6a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83cf6a92",
   "metadata": {},
   "source": [
    "### 2) Build a Sequential LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c758b1bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new = df[[\"sentiment\", \"text\"]]\n",
    "df_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb59e19f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae112d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_tags(string):\n",
    "    removelist = \"\"\n",
    "    result = re.sub('RT','',string) # Remove RT from text         \n",
    "    result = result.lower()\n",
    "    return result\n",
    "df_new['text'] = df_new['text'].apply(lambda cw : remove_tags(cw))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a92fcfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "df_new['text'] = df_new['text'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop_words)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b9cb2b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lemmatizing text\n",
    "w_tokenizer = nltk.tokenize.WhitespaceTokenizer()\n",
    "lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "def lemmatize_text(text):\n",
    "    st = \"\"\n",
    "    for w in w_tokenizer.tokenize(text):\n",
    "        st = st + lemmatizer.lemmatize(w) + \" \"\n",
    "    return st\n",
    "df_new['text'] = df_new.text.apply(lemmatize_text)\n",
    "df_new.sample(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b375ee53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding Labels\n",
    "reviews = df_new[\"text\"].values\n",
    "labels = df_new[\"sentiment\"].values\n",
    "encoder = LabelEncoder()\n",
    "encoded_labels = encoder.fit_transform(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de07e2f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Test Split\n",
    "train_sentences, test_sentences, train_labels, test_labels = train_test_split(reviews, encoded_labels, stratify = encoded_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14fc9239",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenizing Sentences\n",
    "vocab_size = 3000 \n",
    "oov_tok = ''\n",
    "embedding_dim = 100\n",
    "max_length = 200 \n",
    "padding_type='post'\n",
    "trunc_type='post'\n",
    "\n",
    "tokenizer = Tokenizer(num_words = vocab_size, oov_token=oov_tok)\n",
    "tokenizer.fit_on_texts(train_sentences)\n",
    "word_index = tokenizer.word_index\n",
    "\n",
    "train_sequences = tokenizer.texts_to_sequences(train_sentences)\n",
    "train_padded = pad_sequences(train_sequences, padding='post', maxlen=max_length)\n",
    "\n",
    "test_sequences = tokenizer.texts_to_sequences(test_sentences)\n",
    "test_padded = pad_sequences(test_sequences, padding='post', maxlen=max_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d26d2f64",
   "metadata": {},
   "source": [
    "### Building Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad091301",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.layers.Embedding(vocab_size, embedding_dim, input_length=max_length),\n",
    "    keras.layers.Bidirectional(keras.layers.LSTM(64)),\n",
    "    keras.layers.Dense(24, activation='relu'),\n",
    "    keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "# compile model\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "# model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b90ffb63",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 5\n",
    "history = model.fit(train_padded, train_labels, \n",
    "                    epochs = num_epochs, verbose = 1, \n",
    "                    validation_split = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61982454",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = model.predict(test_padded)\n",
    "pred_labels = []\n",
    "\n",
    "for i in prediction:\n",
    "    if i >= 0.5:\n",
    "        pred_labels.append(1)\n",
    "    else:\n",
    "        pred_labels.append(0)\n",
    "print(\"Accuracy of prediction on test set : \", accuracy_score(test_labels,pred_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb312e8a",
   "metadata": {},
   "source": [
    "### 3) Based on the model, check the sentiment for the following two sentences\n",
    "\n",
    "a. 'He is a great leader.'\n",
    "\n",
    "b. 'He is a terrible leader.'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e71af92",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = [\"He is a great leader.\", \n",
    "            \"He is a terrible leader.\"]\n",
    "\n",
    "sequences = tokenizer.texts_to_sequences(sentence)\n",
    "\n",
    "padded = pad_sequences(sequences, padding='post', maxlen=max_length)\n",
    "prediction = model.predict(padded)\n",
    "pred_labels = []\n",
    "\n",
    "for i in prediction:\n",
    "    if i >= 0.5:\n",
    "        pred_labels.append(1)\n",
    "    else:\n",
    "        pred_labels.append(0)\n",
    "        \n",
    "for i in range(len(sentence)):\n",
    "    print(sentence[i])\n",
    "    if pred_labels[i] == 1:\n",
    "        s = 'Positive'\n",
    "    else:\n",
    "        s = 'Negative'\n",
    "    print(\"Predicted sentiment : \",s)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
